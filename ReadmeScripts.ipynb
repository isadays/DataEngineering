{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Isabela P. L. Dias\n",
        "\n",
        "M.Sc. in Physics and  data scientist\n",
        "\n",
        "✉: isabeladiaspl@icloud.com\n",
        "\n",
        "LinkedIn: [diasplisabela](https://www.linkedin.com/in/diasplisabela/)\tGithub: [isadays](https://github.com/isadays/)\n",
        "\n",
        "São Paulo, Brazil.\n"
      ],
      "metadata": {
        "id": "-KQlZfslAmy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1 - Data Extraction**\n",
        "\n",
        "Download data from ONS and Eneva websites, you can do it manually. (Bonus:\n",
        "Create an automated script to download the data from ONS)."
      ],
      "metadata": {
        "id": "SOixMI5r5wCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**: Python scripting. Note: the data from ONS is filtered according to the relevant columns for our analysis. The following script works on command prompt and Jupyter.\n",
        "\n",
        "**Required libraries**: pandas, requests, io, sys, os and logging.\n"
      ],
      "metadata": {
        "id": "htP8ouP5Duum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Extraction from ONS AND Eneva\n",
        "python3 data_extraction.py both 2022 1 12\n",
        "# Data Extraction from ONS\n",
        "python3 data_extraction.py ons 2022 1 12\n",
        "#Data Extraction from Eneva\n",
        "python3 data_extraction.py eneva\n",
        "#Data Extraction from ONS for a specified range of years.\n",
        "python3 data_extraction.py historical_ons 16 21"
      ],
      "metadata": {
        "id": "SdnuzsBS55kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *data_extraction.py* contains a main execution block that checks the command-line arguments provided when running the script. We have three possible commands: 'ons', 'eneva', and 'both'.\n",
        "\n",
        "The 'ons' command expects three additional arguments: year, start_month, and end_month. It extracts ONS data for the specified time period.\n",
        "\n",
        "The 'eneva' command extracts Eneva data without any additional arguments.\n",
        "\n",
        "The 'both' command expects three additional arguments (year, start_month, and end_month). It extracts ONS data for the specified time period and then Eneva data.\n",
        "\n",
        "The 'historical_ons' command expects two additional arguments (start_year, and final_year). It extracts historical ONS data for a specified range of years.\n",
        "\n",
        "If invalid commands are provided, errors messages are logged."
      ],
      "metadata": {
        "id": "6UXf25zrCz1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Details**"
      ],
      "metadata": {
        "id": "KAomIGkk-sqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script *data_extraction.py* contains two functions:\n",
        "\n",
        "- extract_ONS_data function: The function extracts electricity generation data from the ONS (National System Operator) website given a specified period. The parameters are the year, start_month, end_month, and output_folder. For each month within the specified range, it constructs a URL to download the corresponding CSV file from the ONS website. Upon successful download, it reads the CSV data using *pandas*, selects relevant columns, and saves the processed data to CSV files within the specified output folder.\n",
        "\n",
        "- extract_ONS_hist_data function: This function downloads historical monthly generation data from ONS for a specified range of years. Similar to the previous function, it downloads the CSV files, processes the data to aggregate it monthly, and saves the processed data to CSV files.\n",
        "\n",
        "- extract_eneva_data function: The function retrieves data related to the Eneva company from a specific URL. It downloads an Excel file containing the data and processes it using *pandas*. The function identifies relevant columns, renames them appropriately, and reshapes the data to a long format. After processing, it saves the transformed data to a CSV file in the specified output folder.\n",
        "\n"
      ],
      "metadata": {
        "id": "BqVN5bUtB93I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arguments**"
      ],
      "metadata": {
        "id": "KEO10MV1ErDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- extract_ONS_data function:\n",
        "\n",
        "year: (int) year for which the electricity generation data needs to be extracted.\n",
        "\n",
        "start_month: (int) the starting month from which data should be extracted.\n",
        "\n",
        "end_month: (int) the ending month until which data should be extracted.\n",
        "\n",
        "output_folder: (str, optional) the folder where the extracted CSV files will be stored. If not provided, a default folder named *'ONS_data'* will be created in the current directory.\n",
        "\n",
        "- extract_ONS_hist_data:\n",
        "start_year: (int) The starting year from which data should be extracted.\n",
        "\n",
        "end_year: (int) The ending year until which data should be extracted.\n",
        "\n",
        "output_folder: (str, optional) The folder where the extracted CSV files will be stored. If not provided, a default folder named 'ONS_data/monthly' will be created in the current directory.\n",
        "\n",
        "- extract_eneva_data function:\n",
        "\n",
        "output_folder: (str, optional) the folder where the extracted CSV file will be stored. If not provided, a default folder named 'Eneva_data' will be created in the current directory.\n",
        "\n",
        "output_file: (str, optional) the filename for the extracted CSV file. If not provided, a default filename *'Eneva_data.csv'* will be used.\n"
      ],
      "metadata": {
        "id": "FBzTGzQKEpX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2- Data Aggregation**"
      ],
      "metadata": {
        "id": "dn6bfO7TNmh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**Python scripting. Script data_aggregation.py"
      ],
      "metadata": {
        "id": "ZIpaaVX6RUsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Required Libraries**: This script requires external libraries such as *pandas*, *numpy*, *re* and *sqlalchemy*."
      ],
      "metadata": {
        "id": "Ze1PejDTRXoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python data_aggregation.py\n"
      ],
      "metadata": {
        "id": "x_UJDgNNVjSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The execution of this script **requires** the previous execution of the SCRIPT *data_extraction.py* for both 2022 1 12 and for historical_ons 16 21\n"
      ],
      "metadata": {
        "id": "NW3bZ4ZcRvNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The code generates a SQLite database, as indicated by the database_url parameter used in the create_engine function from SQLAlchemy. The specified URL 'sqlite:///task_code.db' sets a SQLite database named task_code.db is created or connected to in the current working directory.\n"
      ],
      "metadata": {
        "id": "LRWzDBUsPdMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Database Creation and Connection Engine Creation: The create_engine(database_url) function initializes a new SQLAlchemy engine instance. In this case, it connects to a SQLite database file named task_code.db.\n",
        "\n",
        "- Base.metadata.create_all(engine): This line creates all the tables in the database based on the classes (ONSMonthly, ONSHistQuarterlyData, ONSQuarterly, EnevaProduction) that were defined and inherited from Base, which is SQLAlchemy's declarative base.\n",
        "\n",
        "- Data Insertion and SQL Views: The functions load_ONS_hist_quarterly_data(), load_ONS_data(), and load_Eneva_data() are designed to process data from CSV files generated after the execution of the script *data_extraction.py* .\n",
        "They also define SQL views through the CREATE VIEW IF NOT EXISTS SQL statements. These views are stored queries that allow you to encapsulate the query logic and treat it like a table. They don’t store data; rather, they save a query that can be run whenever the view is referenced.\n",
        "\n",
        "Attention: The database file (task_code.db) gets created in the directory from which the Python script is executed. If the file doesn't exist, SQLite and SQLAlchemy will create it when attempting to connect for the first time.\n",
        "\n",
        "In summary, the code generates SQLite database and also defines its structure, populates it with data, and creates views for easier data retrieval."
      ],
      "metadata": {
        "id": "MfzdOKRtwpph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading Functions**\n",
        "There are three main functions to load and process data, then store it in the database:\n",
        "\n",
        "- load_ONS_hist_quarterly_data()\n",
        "This function processes historical quarterly data from ONS.The function CSV files from the monthly folder, aggregates data by quarter, and inserts the aggregated results into the ons_hist_quarterly_data table. It also creates several SQL views based on the aggregated data. This corresponds to the historical data from ONS.\n",
        "\n",
        "- load_ONS_data()\n",
        "Similar to the previous function but designed to handle both monthly and quarterly ONS data. The function loads the data, aggregates it accordingly, and stores the results in the ons_monthly_data and ons_quarterly_data tables.\n",
        "The function also creates SQL views that summarize the data on different granularities (monthly and quarterly) and for different categories.\n",
        "\n",
        "- load_Eneva_data(): This function is tailored for loading and processing a specific CSV file containing Eneva's production data. It transforms the data using a pivot table, maps the columns to the corresponding table fields, and inserts the data into the eneva_production table.\n"
      ],
      "metadata": {
        "id": "wQZ6Wd8WwhL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries and resources:**\n",
        "\n",
        "To extract the datasets from Eneva and ONS, I used the following libraries:\n",
        "\n",
        "1. [pandas (import pandas as pd)](https://pandas.pydata.org/):\n",
        "\n",
        "*pandas* is a library for data manipulation and analysis in Python. We will use this library for data analysis also, task 5. It provides data structures such as DataFrame. In my code, *pandas* is used for reading the CSV files, through *pd.read_csv* and Excel files, through *pd.read_excel*, and writing data back to CSV files, through *to_csv*.\n",
        "\n",
        "2. [requests (import requests)](https://requests.readthedocs.io/en/latest/):\n",
        "\n",
        "*requests* is a library for making HTTP requests. In my code, *requests* is used to fetch data from URLs (which was required in the task).  \n",
        "\n",
        "3. [io (from io import StringIO, BytesIO)](https://docs.python.org/3/library/io.html):\n",
        "\n",
        "*io* provides tools for encoding and decoding of data .\n",
        "\n",
        "StringIO allows to treat strings.\n",
        "\n",
        "BytesIO expects bytes-like objects and produces bytes objects.\n",
        "\n",
        "In my code *StringIO* and *BytesIO* are used to convert the HTTP response content (which is a string or bytes) into file-like objects that can be passed to pandas for reading.\n",
        "\n",
        "\n",
        "4. [sys (import sys)](https://docs.python.org/3/library/sys.html):\n",
        "\n",
        "*sys* provides access to some variables used or maintained by the Python interpreter that interact strongly with the interpreter. In my code, *sys.argv* is used to access command-line arguments passed to the script when it's executed.\n",
        "\n",
        "5. [os (import os)](https://docs.python.org/3/library/os.html):\n",
        "\n",
        "*os* provides a way of using operating system-dependent functionalities in Python. In my code, *os.makedirs* is used to create directories to store downloaded files if they do not already exist.\n",
        "\n",
        "6. [logging (import logging)](https://docs.python.org/3/library/logging.html):\n",
        "\n",
        "logging is a standard Python library module that provides functions and classes which implement a flexible event logging system for applications and libraries. In my code, I used logging to log messages such as INFO and ERROR, essential for debugging and monitoring the execution of the script.\n",
        "\n",
        "\n",
        "7. [SQLAlchemy](https://www.sqlalchemy.org/)\n",
        "\n",
        "SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL.\n",
        "\n",
        "\n",
        "In these codes, we use the following functions from SQLAlchemy library:\n",
        "\n",
        "create_engine is used to initialize the connection to the database. The engine you create is responsible for establishing the connection to your database and serves as the source of database connectivity.It requires a database URL that indicates database dialect and connection arguments. For instance, I used 'sqlite:///task_code.db'.\n",
        "\n",
        "Column: is used to define a column in a table.\n",
        "\n",
        "\n",
        "Integer, String, Float, DateTime: These are types that you assign to Column instances to define the type of data each column holds\n",
        "\n",
        "text:This is used to create textual SQL expressions.\n",
        "\n",
        "\n",
        "declarative_base: This function returns a base class for declarative class definitions.\n",
        "\n",
        "sessionmaker: A Session establishes all conversations with the database."
      ],
      "metadata": {
        "id": "xQxH11mM6N4o"
      }
    }
  ]
}